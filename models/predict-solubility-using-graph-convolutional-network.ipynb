{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit \n",
    "\n",
    "https://medium.com/@tejpal.abhyuday/application-of-gnn-for-calculating-the-solubility-of-molecule-graph-level-prediction-8bac5fabf600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting molecule solubility using graph neural networks\n",
    "\n",
    "The goal of using graph-based representations in the `torch_geometric` library is to enable the application of graph neural networks (GNNs) and other graph-based machine learning techniques for tasks such as predicting solubility or other chemical properties. GNNs can operate directly on these graph structures, taking into account the connectivity of atoms and the associated node and edge features to make predictions.\n",
    "\n",
    "[Source: ChatGPT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ESOL dataset\n",
    "\n",
    "The ESOL dataset, which stands for \"Extended Solubility\", is a dataset commonly used in the field of cheminformatics and machine learning for predicting the solubility of chemical compounds. The dataset contains information about the solubility of various organic molecules in water.\n",
    "\n",
    "1. **Graph Representation**: Each chemical compound is represented as a graph, where atoms are nodes, and chemical bonds are edges. This graph representation captures the connectivity and structure of the molecule.\n",
    "\n",
    "2. **Node Features**: The node feature vectors, in this case, typically represent the properties of individual atoms within the molecule. These features can include:\n",
    "\n",
    "   - **Atom Type**: Each atom is assigned a specific atom type based on its element (e.g., carbon, hydrogen, oxygen, etc.). This is often one-hot encoded or represented as a categorical feature.\n",
    "\n",
    "   - **Atomic Charges**: The partial charges on each atom, which describe the distribution of electric charge within the molecule.\n",
    "\n",
    "   - **Hybridization**: Information about the hybridization state of each atom (e.g., sp3, sp2, sp).\n",
    "\n",
    "   - **Atomic Mass**: The mass of each atom.\n",
    "\n",
    "   - **Formal Charge**: The formal charge on each atom.\n",
    "\n",
    "   - **Other Atom-specific Properties**: Depending on the specific implementation, additional atom-specific properties may also be included as node features.\n",
    "\n",
    "3. **Edge Features**: In addition to node features, edge features can be included in the graph representation. These features typically describe the type of chemical bond between connected atoms (e.g., single, double, or triple bonds) and may also include bond distances or bond angles.\n",
    "\n",
    "4. **Graph Structure**: The graph structure itself is represented by adjacency matrices or edge lists, which define how atoms are connected by chemical bonds.\n",
    "\n",
    "[Source: ChatGPT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "source": [
    "from torch_geometric.datasets import MoleculeNet\n",
    " \n",
    "# https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.MoleculeNet.html#torch_geometric.datasets.MoleculeNet\n",
    "DATA = MoleculeNet(root=\".\", name=\"ESOL\")\n",
    "DATA"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "source": [
    "print(\"Dataset type: \", type(DATA))\n",
    "print(\"Number of features per graph node: \", DATA.num_features)\n",
    "print(\"Number of distinct target values (solubilities): \", DATA.num_classes)\n",
    "print(\"Number of graphs: \", len(DATA))\n",
    "print(\"Example graph: \", DATA[0])\n",
    "print(\"Number of nodes in example graph: \", DATA[0].num_nodes)\n",
    "print(\"Number of edges in example graph: \", DATA[0].num_edges)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "source": [
    "# nodes of example graph \n",
    "DATA[0].x # shape: [num_nodes, num_node_features]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "source": [
    "# the target value of the example graph is its solubility\n",
    "DATA[0].y"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "source": [
    "# the edges of the example graph are in sparse Coordinate Format (COO)\n",
    "# (also called adjacency list: https://distill.pub/2021/gnn-intro/\n",
    "DATA[0].edge_index.t() # shape [num_edges, 2]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "source": [
    "# edge attributes of example graph\n",
    "DATA[0].edge_attr # shape [num_edges, num_edge_features]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize one of the molecules in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "Chem.MolFromSmiles(DATA[0][\"smiles\"])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a Graph Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F \n",
    "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "\n",
    "EMBEDDING_DIM = 64\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        self.initial_conv = GCNConv( # The graph convolutional operator from the “Semi-supervised Classification with Graph Convolutional Networks” paper\n",
    "          in_channels=DATA.num_features, # number of features per node of graph before transformation\n",
    "          out_channels=EMBEDDING_DIM # number of features per node of graph after transformation\n",
    "        )\n",
    "        self.conv1 = GCNConv(EMBEDDING_DIM, EMBEDDING_DIM)\n",
    "        self.conv2 = GCNConv(EMBEDDING_DIM, EMBEDDING_DIM)\n",
    "        self.conv3 = GCNConv(EMBEDDING_DIM, EMBEDDING_DIM)\n",
    "        self.out = Linear(\n",
    "          in_features=EMBEDDING_DIM*2, # we stack the different global pooling aggregations below\n",
    "          out_features=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch_index):\n",
    "        # First Conv layer\n",
    "        hidden = self.initial_conv(x, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "\n",
    "        # Other Conv layers\n",
    "        hidden = self.conv1(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "        hidden = self.conv2(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "        hidden = self.conv3(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "          \n",
    "        # Global Pooling (stack different aggregations over nodes of graph)\n",
    "        hidden = torch.cat([gmp(hidden, batch_index), \n",
    "                            gap(hidden, batch_index)], dim=1)\n",
    "\n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.out(hidden)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "MODEL = GCN()\n",
    "print(MODEL)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in MODEL.parameters()))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Graph Convolutional Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "NUM_GRAPHS_PER_BATCH = 64\n",
    "\n",
    "# Use GPU for training (if available)\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "source": [
    "def train(model, data):\n",
    "  model = model.to(DEVICE)\n",
    "\n",
    "  loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0007)\n",
    "\n",
    "  data_size = len(data)\n",
    "  train_loader = DataLoader(\n",
    "    data[:int(data_size * 0.8)], \n",
    "    batch_size=NUM_GRAPHS_PER_BATCH, \n",
    "    shuffle=True\n",
    "  )\n",
    "\n",
    "  for batch in train_loader:\n",
    "    # Use GPU\n",
    "    batch.to(DEVICE)  \n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad() \n",
    "    # Passing the node features and the edge info\n",
    "    pred, embedding = model(batch.x.float(), batch.edge_index, batch.batch) \n",
    "    # Calculating the loss and gradients\n",
    "    loss = loss_fn(pred, batch.y)     \n",
    "    loss.backward()  \n",
    "    # Update using the gradients\n",
    "    optimizer.step()   \n",
    "  return loss, embedding\n",
    "\n",
    "def train_wrapper():\n",
    "  print(\"Starting training...\")\n",
    "  losses = []\n",
    "  for epoch in range(2000): \n",
    "      loss, h = train(MODEL, DATA)\n",
    "      losses.append(loss)\n",
    "      if epoch % 100 == 0: \n",
    "        print(f\"Epoch {epoch} | Train Loss {loss}\")\n",
    "  return losses \n",
    "\n",
    "LOSSES = train_wrapper()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize training loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_train_loss(): \n",
    "  losses_float = [float(loss.cpu().detach().numpy()) for loss in LOSSES] \n",
    "  loss_indices = range(len(losses_float))\n",
    "  ax = sns.lineplot(x=loss_indices, y=losses_float)\n",
    "  ax.set(xlabel='Epoch', ylabel='Loss')\n",
    "  \n",
    "plot_train_loss()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict solubility on test data and compare with true solubilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd \n",
    "\n",
    "def predict(model, data): \n",
    "  data_size = len(data)\n",
    "  test_loader = DataLoader(\n",
    "    data[int(data_size * 0.8):], \n",
    "    batch_size=NUM_GRAPHS_PER_BATCH, \n",
    "    shuffle=True\n",
    "  )\n",
    "\n",
    "  # Analyze the results for one batch\n",
    "  test_batch = next(iter(test_loader))\n",
    "\n",
    "  with torch.no_grad():\n",
    "    test_batch.to(DEVICE)\n",
    "    pred, embed = model(test_batch.x.float(), test_batch.edge_index, test_batch.batch) \n",
    "    df = pd.DataFrame()\n",
    "    df[\"y_real\"] = test_batch.y.tolist()\n",
    "    df[\"y_pred\"] = pred.tolist()\n",
    "\n",
    "  df[\"y_real\"] = df[\"y_real\"].apply(lambda row: row[0])\n",
    "  df[\"y_pred\"] = df[\"y_pred\"].apply(lambda row: row[0])\n",
    "\n",
    "  axes = sns.scatterplot(data=df, x=\"y_real\", y=\"y_pred\")\n",
    "  axes.set_xlabel(\"Real Solubility\")\n",
    "  axes.set_ylabel(\"Predicted Solubility\")\n",
    "\n",
    "predict(MODEL, DATA)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_env",
   "language": "python",
   "name": "gnn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
